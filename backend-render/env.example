# Backend Environment Variables for Local Development

# Database (SQLite for local testing)
DATABASE_URL=sqlite:///./data/webui.db

# Redis (optional for local testing)
REDIS_URL=redis://localhost:6379

# WebUI Configuration
WEBUI_SECRET_KEY=your-secret-key-here
WEBUI_NAME=OpenWebUI
WEBUI_URL=http://localhost:6969

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:6969,http://127.0.0.1:6969

# Features
ENABLE_SIGNUP=true
ENABLE_LOGIN_FORM=true
ENABLE_OLLAMA_API=true
ENABLE_OPENAI_API=true
ENABLE_DIRECT_CONNECTIONS=true
ENABLE_IMAGE_GENERATION=true
ENABLE_CODE_EXECUTION=false
ENABLE_CODE_INTERPRETER=false

# Environment
ENV=development

# ===== BACKEND-ONLY API CONFIGURATION =====
# All API keys are managed server-side and NEVER exposed to frontend

# OpenAI API Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_API_BASE_URL=https://api.openai.com/v1
ENABLE_OPENAI_API=true

# OpenRouter API Configuration
OPENROUTER_API_KEY=your-openrouter-api-key-here
OPENROUTER_API_BASE_URL=https://openrouter.ai/api/v1
ENABLE_OPENROUTER_API=false

# Atlas Cloud API Configuration
ATLAS_CLOUD_API_KEY=your-atlas-cloud-api-key-here
ATLAS_CLOUD_API_BASE_URL=https://api.atlascloud.ai/v1
ENABLE_ATLAS_CLOUD_API=false

# Anthropic Claude API Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_API_BASE_URL=https://api.anthropic.com
ENABLE_ANTHROPIC_API=false

# Google AI (Gemini) API Configuration
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_API_BASE_URL=https://generativelanguage.googleapis.com
ENABLE_GOOGLE_API=false

# Cohere API Configuration
COHERE_API_KEY=your-cohere-api-key-here
COHERE_API_BASE_URL=https://api.cohere.ai
ENABLE_COHERE_API=false

# Mistral AI API Configuration
MISTRAL_API_KEY=your-mistral-api-key-here
MISTRAL_API_BASE_URL=https://api.mistral.ai
ENABLE_MISTRAL_API=false

# Perplexity API Configuration
PERPLEXITY_API_KEY=your-perplexity-api-key-here
PERPLEXITY_API_BASE_URL=https://api.perplexity.ai
ENABLE_PERPLEXITY_API=false

# Ollama Local Configuration
OLLAMA_BASE_URL=http://localhost:11434
ENABLE_OLLAMA_API=true

# Hugging Face Inference API Configuration
HUGGINGFACE_API_KEY=your-huggingface-api-key-here
HUGGINGFACE_API_BASE_URL=https://api-inference.huggingface.co
ENABLE_HUGGINGFACE_API=false

# Replicate API Configuration
REPLICATE_API_KEY=your-replicate-api-key-here
REPLICATE_API_BASE_URL=https://api.replicate.com
ENABLE_REPLICATE_API=false

# Together AI API Configuration
TOGETHER_API_KEY=your-together-api-key-here
TOGETHER_API_BASE_URL=https://api.together.xyz
ENABLE_TOGETHER_API=false

# DeepSeek API Configuration
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_API_BASE_URL=https://api.deepseek.com
ENABLE_DEEPSEEK_API=false

# Zhipu AI (GLM) API Configuration
ZHIPU_API_KEY=your-zhipu-api-key-here
ZHIPU_API_BASE_URL=https://open.bigmodel.cn/api/paas/v4
ENABLE_ZHIPU_API=false

# Baichuan API Configuration
BAICHUAN_API_KEY=your-baichuan-api-key-here
BAICHUAN_API_BASE_URL=https://api.baichuan-ai.com
ENABLE_BAICHUAN_API=false

# Qwen (Alibaba) API Configuration
QWEN_API_KEY=your-qwen-api-key-here
QWEN_API_BASE_URL=https://dashscope.aliyuncs.com/api/v1
ENABLE_QWEN_API=false

# Model Configuration
# Add your preferred models for each provider
OPENAI_MODELS=gpt-4,gpt-4-turbo,gpt-3.5-turbo,gpt-4o,text-embedding-ada-002
OPENROUTER_MODELS=openai/gpt-4,anthropic/claude-3-opus,meta-llama/llama-2-70b-chat
ATLAS_CLOUD_MODELS=atlas-7b,atlas-13b,atlas-70b
ANTHROPIC_MODELS=claude-3-opus-20240229,claude-3-sonnet-20240229,claude-3-haiku-20240307
GOOGLE_MODELS=gemini-pro,gemini-pro-vision,text-embedding-004
COHERE_MODELS=command,command-light,embed-english-v3.0
MISTRAL_MODELS=mistral-large-latest,mixtral-8x7b-instruct,mistral-7b-instruct
PERPLEXITY_MODELS=llama-3.1-8b-instruct,llama-3.1-70b-instruct,mixtral-8x7b-instruct
HUGGINGFACE_MODELS=microsoft/DialoGPT-medium,google/flan-t5-base
REPLICATE_MODELS=meta/llama-2-70b-chat,stability-ai/stable-diffusion
TOGETHER_MODELS=togethercomputer/llama-2-70b-chat,meta-llama/Llama-2-70b-chat-hf
DEEPSEEK_MODELS=deepseek-chat,deepseek-coder
ZHIPU_MODELS=glm-4,glm-4v,glm-3-turbo
BAICHUAN_MODELS=Baichuan2-Turbo,Baichuan2-13B-Chat
QWEN_MODELS=qwen-turbo,qwen-plus,qwen-max

# Advanced Configuration
# Set to true to enable streaming responses
ENABLE_STREAMING=true

# Set to true to enable function calling
ENABLE_FUNCTION_CALLING=true

# Set to true to enable vision models
ENABLE_VISION_MODELS=true

# Set to true to enable embedding models
ENABLE_EMBEDDING_MODELS=true

# Rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# Maximum tokens per request
MAX_TOKENS_PER_REQUEST=4000

# Default temperature for completions
DEFAULT_TEMPERATURE=0.7

# Default max tokens for completions
DEFAULT_MAX_TOKENS=1000
